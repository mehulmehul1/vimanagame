# ğŸš€ Visionary: æ•°æ®å‡†å¤‡ä¸ ONNX å¯¼å‡ºæŒ‡å—

Visionary åŸºäºæ ‡å‡†åŒ–çš„ **Gaussian Generator** åè®®ï¼šåªè¦ä½ çš„ 3DGS ç³»åˆ—ç®—æ³•ï¼ˆç»å…¸ / ç»“æ„åŒ– / 4DGSã€Avatarï¼Œæˆ–ä»»æ„è‡ªå®šä¹‰å˜ä½“ï¼‰èƒ½å¯¼å‡º ONNX å¹¶è¾“å‡ºé€å¸§çš„é«˜æ–¯å±æ€§ï¼ˆä½ç½®ã€å°ºåº¦ã€æ—‹è½¬ã€é¢œè‰²ç­‰ï¼‰ï¼Œå°±å¯ä»¥åœ¨æ— éœ€ä¿®æ”¹ WebGPU æ¸²æŸ“å™¨æˆ–ç€è‰²å™¨çš„æƒ…å†µä¸‹æ¥å…¥æŸ¥çœ‹å™¨ã€‚æœ¬æ–‡æ¡£ä¸­çš„å„ä¸ªæµæ°´çº¿ï¼ˆAvatarã€4DGSã€Scaffold-GS ç­‰ï¼‰å¯ä½œä¸ºå‚è€ƒå®ç°ï¼Œä½ å¯ä»¥å°†å®ƒä»¬å½“ä½œæ¨¡æ¿æŠŠè‡ªå·±çš„æ–¹æ³•é€‚é…åˆ° Visionary è¿è¡Œæ—¶ã€‚

ä¸ºäº†è®©ä½ çš„ Gaussian Generator åœ¨ Visionary ä¸Šé«˜æ•ˆè¿è¡Œï¼Œæ¨èä¸€äº›é’ˆå¯¹ WebGPU è¿è¡Œæ—¶çš„ ONNX å¯¼å‡ºå®ç”¨æŠ€å·§ï¼š

- **å¯¼å‡ºä¾¿äºå›¾æ•è·çš„æ¨¡å‹ã€‚** å°½é‡é¿å…åŠ¨æ€æ§åˆ¶æµå’Œé«˜åº¦åŠ¨æ€çš„å¼ é‡å½¢çŠ¶ï¼Œä½¿ ONNX Runtime WebGPU èƒ½å¯ç”¨ graph captureã€‚ä¿æŒç¨³å®šå›¾ï¼ˆå›ºå®š batch/åºåˆ—å½¢çŠ¶ã€æ—  Python/Loop é£æ ¼ç®—å­ã€æ— å¥‡å¼‚ dtypeï¼‰èƒ½åœ¨æ•è·åæ˜¾è‘—æé€Ÿã€‚
- **éµå¾ªä¸‹æ–‡ç¤ºä¾‹çš„ç´¢å¼•æ¨¡å¼ã€‚** åœ¨åˆ‡ç‰‡æˆ–ç´¢å¼•é«˜æ–¯å±æ€§ï¼ˆä½ç½®ã€å°ºåº¦ã€æ—‹è½¬ã€é¢œè‰²ç­‰ï¼‰æ—¶ï¼Œå°½é‡å¤ç”¨æ–‡æ¡£ä¸­å‚è€ƒæµæ°´çº¿çš„ç´¢å¼•ç­–ç•¥ï¼Œä¿æŒå†…å­˜å¸ƒå±€è¿ç»­å¹¶ä¸ WebGPU kernel åŠåå¤„ç†å·¥å…·å…¼å®¹ã€‚
- **ç”¨æ‰‹å†™å®ç°æ›¿æ¢å†…ç½® Norm ç®—å­ã€‚** ONNX Runtime çš„ WebGPU åç«¯åœ¨ Normã€LayerNormalizationã€RMSNorm ä¸Šå­˜åœ¨å·²çŸ¥é—®é¢˜å’Œæ€§èƒ½å·®å¼‚ï¼Œå»ºè®®å¯¼å‡ºå‰æ”¹å†™ä¸ºåŸºç¡€ç®—å­ç»„åˆï¼ˆå¦‚ `ReduceMean` + `Sub` + `Mul` + `Add`ï¼‰ï¼Œæˆ–å¯¼å‡ºåç”¨é¢„å¤„ç†è„šæœ¬æ›¿æ¢ã€‚
- **é¿å…å·¨å‹å•ä¸ª `Concat` / `Split`ã€‚** WebGPU shader å—èµ„æºç»‘å®šæ•°é‡é™åˆ¶ï¼Œå¦‚æœæ¨¡å‹æœ‰éå¸¸å¤§çš„ `Concat` æˆ– `Split`ï¼ˆå¤§é‡è¾“å…¥/è¾“å‡ºï¼‰ï¼Œè¯·æ‹†æˆå¤šæ®µ `Concat`/`Split` å†åˆå¹¶ï¼Œå¯æå‡ç¼–è¯‘ç¨³å®šæ€§ã€‚

æœ¬ç»Ÿä¸€æŒ‡å—æ¶µç›–äº†ä¸º **Visionary Viewer** å‡†å¤‡ã€è®­ç»ƒå’Œå¯¼å‡ºæ•°æ®çš„æµç¨‹ã€‚å®ƒåŒ…æ‹¬é’ˆå¯¹å¯åŠ¨ç”»åŒ– Avatarã€åŠ¨æ€åœºæ™¯ (4DGS)ã€ç»“æ„åŒ–é™æ€åœºæ™¯ (Scaffold-GS) å’Œé€šç”¨æ ¼å¼è½¬æ¢çš„è¯´æ˜ã€‚


## ğŸ“‹ ç›®å½•
1. [å¯åŠ¨ç”»åŒ– Avatar (åŸºäº SMPL-X)](#1-å¯åŠ¨ç”»åŒ–-avatar-onnx-æ¨¡å‹)
2. [4D Gaussian Splatting (åŠ¨æ€åœºæ™¯)](#2-4d-gaussian-splatting-4dgs-å¯¼å‡º)
3. [Scaffold-GS (ç»“æ„åŒ–é™æ€åœºæ™¯)](#3-scaffold-gs-å¯¼å‡º)
4. [é€šç”¨ 3DGS æ ¼å¼è½¬æ¢](#4-é€šç”¨-3dgs-æ ¼å¼è½¬æ¢å·¥å…·)

---

## 1. å¯åŠ¨ç”»åŒ– Avatar ONNX æ¨¡å‹

ä½¿ç”¨æ­¤æµç¨‹ç”Ÿæˆç”± SMPL-X åŠ¨ä½œæ•°æ®é©±åŠ¨çš„å¯åŠ¨ç”»åŒ– Avatarã€‚

### **1.1 ç¯å¢ƒé…ç½®**

**åˆ›å»ºå¹¶æ¿€æ´»ç¯å¢ƒ (Python 3.10)**

```bash
conda create -n visionary_avatar python==3.10 -y
conda activate visionary_avatar
```

**å®‰è£…æ ¸å¿ƒæ¡†æ¶**

```bash
pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121
pip install -U xformers==0.0.28.post3 --index-url https://download.pytorch.org/whl/cu121
pip install ninja psutil tb-nightly
```

**å®‰è£…è‡ªå®šä¹‰ä¾èµ–**

> **æ•…éšœæ’é™¤æç¤ºï¼š** å¦‚æœåœ¨å®‰è£… **PyTorch3D** æˆ– **Gaussian Rasterization** æ—¶é‡åˆ° `ModuleNotFoundError: No module named 'torch'` é”™è¯¯ï¼Œè¯·åœ¨å‘½ä»¤åé™„åŠ  `--no-build-isolation` æ ‡å¿—ã€‚

```bash
# æ ¸å¿ƒ 3D åº“
pip install git+https://github.com/facebookresearch/pytorch3d.git
pip install git+https://github.com/hitsz-zuoqi/sam2/
pip install git+https://github.com/XPixelGroup/BasicSR
pip install git+https://github.com/ashawkey/diff-gaussian-rasterization/

# å…¶ä»–å®ç”¨å·¥å…·
pip install opencv-python roma smplx tqdm scikit-image huggingface_hub[cli] modelscope kornia timm accelerate diffusers==0.32.0 plyfile trimesh matplotlib jaxtyping decord transformers==4.46.2 sentencepiece chumpy gfpgan xfuser onnxruntime-gpu onnx natsort

# é™çº§ Numpy ä»¥ç¡®ä¿å…¼å®¹æ€§
pip install numpy==1.23.5
```

### **1.2 æ¨¡å‹æƒé‡ä¸èµ„æº**

ä» HuggingFace ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹å’Œ GFPGAN æƒé‡ã€‚

```bash
# ç¡®ä¿æ‚¨ä½äº ONNXExample-Avatar ç›®å½•ç»“æ„ä¸­
cd onnx-export\ONNXExample-Avatar

# ä¸‹è½½ä»“åº“
hf download MyNiuuu/Visionary_avatar --local-dir ./Visionary_avatar --local-dir-use-symlinks False

# æ•´ç†æ–‡ä»¶
mv ./Visionary_avatar/pretrained_models .
mv ./Visionary_avatar/gfpgan .

# æ¸…ç†
rm -rf ./Visionary_avatar
```

### **1.3 åŠ¨ä½œæ•°æ®å‡†å¤‡ (AMASS-CMU)**
ä» AMASS æ•°æ®é›†è·å– SMPL-X åŠ¨ä½œåºåˆ—ä»¥é©±åŠ¨ Avatarã€‚

1.  **æ³¨å†Œ/ç™»å½•ï¼š** è®¿é—® [AMASS ç½‘ç«™](https://amass.is.tue.mpg.de) å¹¶ç™»å½•ã€‚
2.  **å¯¼èˆªè‡³ä¸‹è½½ï¼š** å‰å¾€ [ä¸‹è½½é¡µé¢](https://amass.is.tue.mpg.de/download.php)ã€‚
3.  **é€‰æ‹©æ•°æ®é›†ï¼š** æ‰¾åˆ° **CMU** æ•°æ®é›†ã€‚
4.  **ä¸‹è½½ï¼š** ç‚¹å‡» `SMPL-X N` ä¸‹è½½ zip æ–‡ä»¶ã€‚
5.  **è§£å‹ï¼š** å°†å†…å®¹è§£å‹åˆ° `./motions` ç›®å½•ã€‚

### **1.4 ç”Ÿæˆ ONNX Avatar æ¨¡å‹**

**æ‰§è¡Œè¿è¡Œè„šæœ¬ï¼š**

```bash
bash run.sh
```
---

## 2. 4D Gaussian Splatting (4DGS) å¯¼å‡º

ç”¨äºè¿è¡Œ 4DGS é¡¹ç›®å¹¶å°†è®­ç»ƒå¥½çš„åŠ¨æ€åœºæ™¯è¡¨ç¤ºå¯¼å‡ºä¸º ONNX æ ¼å¼çš„æµç¨‹ã€‚

### **2.1 ç¯å¢ƒé…ç½®**

```bash
git clone https://github.com/hustvl/4DGaussians
cd 4DGaussians
git submodule update --init --recursive
conda create -n Gaussians4D python=3.7 
conda activate Gaussians4D
    
# å®‰è£…ä¾èµ–
pip install -r requirements.txt
pip install onnx

# å®‰è£…å­æ¨¡å—
pip install -e submodules/depth-diff-gaussian-rasterization
pip install -e submodules/simple-knn
```

### **2.2 ä»£ç å‡†å¤‡ (å…³é”®æ­¥éª¤)**

è¦å¯¼å‡ºä¸º ONNXï¼Œå¿…é¡»ä¿®æ”¹ 4DGaussians ä»“åº“ä¸­çš„ `train.py` ä»¥ä¿å­˜ hex-plane AABBã€‚

**ä¿®æ”¹ç¬¬ 299-313 è¡Œå·¦å³ï¼š**

*æ›´æ”¹å‰ï¼š*
```python
tb_writer = prepare_output_and_logger(expname)
gaussians = GaussianModel(dataset.sh_degree, hyper)
dataset.model_path = args.model_path
timer = Timer()
scene = Scene(dataset, gaussians, load_coarse=None)
```

*æ›´æ”¹åï¼š*
```python
args.model_path = os.path.join("./output/", expname)
os.makedirs(args.model_path, exist_ok = True)
gaussians = GaussianModel(dataset.sh_degree, hyper)
dataset.model_path = args.model_path
timer = Timer()
scene = Scene(dataset, gaussians, load_coarse=None)
# ä¸º ONNX å¯¼å‡ºæ·»åŠ ï¼š
grid_aabb = scene.gaussians._deformation.deformation_net.get_aabb
args.grid_aabb = [x.cpu().tolist() for x in grid_aabb]
tb_writer = prepare_output_and_logger(expname)
```

*ä¸ºç¡®ä¿è·¯å¾„ä¸€è‡´ï¼Œè¯·**åˆ é™¤**éšåçš„è‡ªåŠ¨ `args.model_path` ç”Ÿæˆé€»è¾‘ï¼ˆUUID ç”Ÿæˆï¼‰ï¼š*
```python
if not args.model_path:
        # if os.getenv('OAR_JOB_ID'):
        #     unique_str=os.getenv('OAR_JOB_ID')
        # else:
        #     unique_str = str(uuid.uuid4())
        unique_str = expname
    
        args.model_path = os.path.join("./output/", unique_str)
    # Set up output folder
    print("Output folder: {}".format(args.model_path))
    os.makedirs(args.model_path, exist_ok = True)
```

### **2.3 æ•°æ®å‡†å¤‡**

*   **åˆæˆåœºæ™¯ï¼š** ä½¿ç”¨ [D-NeRF æ•°æ®é›†](https://github.com/albertpumarola/D-NeRF)ã€‚æ‚¨å¯ä»¥ä» [dropbox](https://www.dropbox.com/scl/fi/cdcmkufncwcikk1dzbgb4/data.zip?rlkey=n5m21i84v2b2xk6h7qgiu8nkg&e=1&dl=0) ä¸‹è½½æ•°æ®é›†ã€‚

*   **çœŸå®åœºæ™¯ï¼š** ä½¿ç”¨ [Neural 3D Video æ•°æ®é›†](https://github.com/facebookresearch/Neural_3D_Video)ã€‚ä¸ºäº†èŠ‚çœå†…å­˜ï¼Œè¯·æå–æ¯ä¸ªè§†é¢‘çš„å¸§å¹¶åº”ç”¨ [COLMAP](https://colmap.github.io/) è·å–åˆå§‹ç‚¹äº‘ã€‚

    1.  **æå–å¸§ï¼š**
        ```bash
        python scripts/preprocess_dynerf.py --datadir data/dynerf/cut_roasted_beef
        ```

    2.  **ç”Ÿæˆç‚¹äº‘ï¼š**
        ```bash
        bash colmap.sh data/dynerf/cut_roasted_beef llff
        ```

    3.  **ä¸‹é‡‡æ ·ç‚¹äº‘ï¼š**
        ```bash
        python scripts/downsample_point.py data/dynerf/cut_roasted_beef/colmap/dense/workspace/fused.ply data/dynerf/cut_roasted_beef/points3D_downsample2.ply
        ```

**ç›®å½•ç»“æ„**
æœ€ç»ˆæ•°æ®é›†åº”æŒ‰å¦‚ä¸‹æ–¹å¼ç»„ç»‡ï¼š

```text
â”œâ”€â”€ data
â”‚   | dnerf 
â”‚     â”œâ”€â”€ hook
â”‚     â”œâ”€â”€ standup 
â”‚     â”œâ”€â”€ ...
â”‚   | dynerf
â”‚     â”œâ”€â”€ cook_spinach
â”‚       â”œâ”€â”€ cam00
â”‚           â”œâ”€â”€ images
â”‚               â”œâ”€â”€ 0000.png
â”‚               â”œâ”€â”€ 0001.png
â”‚               â”œâ”€â”€ 0002.png
â”‚               â”œâ”€â”€ ...
â”‚       â”œâ”€â”€ cam01
â”‚           â”œâ”€â”€ images
â”‚               â”œâ”€â”€ 0000.png
â”‚               â”œâ”€â”€ 0001.png
â”‚               â”œâ”€â”€ ...
â”‚       â”‚ points3D_downsample2.ply
â”‚       â”‚ poses_bounds.npy
â”‚     â”œâ”€â”€ cut_roasted_beef
â”‚     â”œâ”€â”€ ...
```

### **2.4 è®­ç»ƒ**

ç¤ºä¾‹è®­ç»ƒå‘½ä»¤ (D-NeRF `hook` åœºæ™¯)ï¼š

```bash
python train.py -s data/dnerf/hook --port 6017 --expname "dnerf/hook" --configs arguments/dnerf/hook.py 
```
è®­ç»ƒåï¼Œæ£€æŸ¥ç‚¹å’Œè¾“å‡ºä¿å­˜åœ¨ `./output/dnerf/hook` ä¸­ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
```text
â”œâ”€â”€ output
â”‚   | dnerf 
â”‚     â”œâ”€â”€ hook
â”‚        â”œâ”€â”€ point_cloud
â”‚           â”œâ”€â”€ iteration_14000
â”‚              â”œâ”€â”€ deformation.pth
â”‚              â”œâ”€â”€ deformation_accum.pth
â”‚              â”œâ”€â”€ deformation_table.pth
â”‚              â”œâ”€â”€ point_cloud.ply
â”‚        | cfg_args
â”‚     â”œâ”€â”€ standup 
â”‚     â”œâ”€â”€ ...
â”‚   | dynerf
â”‚     â”œâ”€â”€ cook_spinach
â”‚     â”œâ”€â”€ ...
```

### **2.5 å¯¼å‡º ONNX**

åœ¨ 4D-GS ç¯å¢ƒä¸­ï¼Œä½¿ç”¨å¯¼å‡ºè„šæœ¬ï¼ˆç¡®ä¿æ‚¨ä½äº `onnx-export\ONNXExample-4dgs` ç›®å½•ç»“æ„ä¸­ï¼‰ï¼š

```bash
cd onnx-export\ONNXExample-4dgs

python onnx_template.py --ply path/to/output/dnerf/hook/point_cloud/iteration_14000/point_cloud.ply \
                  --out your/prefered/onnxpath/gaussians4d.onnx
```
---

## 3. Scaffold-GS å¯¼å‡º

è¿è¡Œ Scaffold-GS å¹¶å°†è®­ç»ƒå¥½çš„é™æ€åœºæ™¯å¯¼å‡ºä¸º ONNX çš„æµç¨‹ã€‚

### **3.1 ç¯å¢ƒé…ç½®**

```bash
git clone https://github.com/city-super/Scaffold-GS.git --recursive
cd Scaffold-GS

# ä»…é™ Windows: SET DISTUTILS_USE_SDK=1 
conda env create --file environment.yml
conda activate scaffold_gs
pip install onnx
```

### **3.2 æ•°æ®å‡†å¤‡**

åˆ›å»ºä¸€ä¸ª `data/` æ–‡ä»¶å¤¹ã€‚æ•°æ®åº”éµå¾ªæ ‡å‡†çš„ Colmap ç»“æ„ï¼š

```
data/
â”œâ”€â”€ dataset_name
â”‚   â”œâ”€â”€ scene1/
â”‚   â”‚   â”œâ”€â”€ images
â”‚   â”‚   â”‚   â”œâ”€â”€ IMG_0.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ IMG_1.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ sparse/
â”‚   â”‚       â””â”€â”€0/
â”‚   â”œâ”€â”€ scene2/
â”‚   â”‚   â”œâ”€â”€ images
â”‚   â”‚   â”‚   â”œâ”€â”€ IMG_0.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ IMG_1.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ sparse/
â”‚   â”‚       â””â”€â”€0/
...
```

**å…¬å¼€æ•°æ®**
æ‚¨å¯ä»¥ä¸‹è½½æ ‡å‡†æ•°æ®é›†å¹¶å°†å®ƒä»¬è§£å‹åˆ° `data/` æ–‡ä»¶å¤¹ä¸­ï¼š

*   **BungeeNeRF:** å¯åœ¨ [Google Drive](https://drive.google.com/file/d/1nBLcf9Jrr6sdxKa1Hbd47IArQQ_X8lww/view?usp=sharing) æˆ– [ç™¾åº¦ç½‘ç›˜ (æå–ç : 4whv)](https://pan.baidu.com/s/1AUYUJojhhICSKO2JrmOnCA) ä¸‹è½½ã€‚
*   **MipNeRF360:** ç”±è®ºæ–‡ä½œè€…æä¾› [åœ¨æ­¤å¤„](https://jonbarron.info/mipnerf360/)ã€‚æˆ‘ä»¬æµ‹è¯•çš„åœºæ™¯åŒ…æ‹¬ï¼š`bicycle, bonsai, counter, garden, kitchen, room, stump`ã€‚
*   **Tanks&Temples / Deep Blending:** ç”± 3D-Gaussian-Splatting å›¢é˜Ÿæ‰˜ç®¡ [åœ¨æ­¤å¤„](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/datasets/input/tandt_db.zip)ã€‚

**è‡ªå®šä¹‰æ•°æ®**
å¯¹äºè‡ªå®šä¹‰æ•°æ®ï¼š
1.  ä½¿ç”¨ [Colmap](https://colmap.github.io/) å¤„ç†æ‚¨çš„å›¾åƒåºåˆ—ï¼Œä»¥è·å– SfM ç‚¹å’Œç›¸æœºä½å§¿ã€‚
2.  ç¡®ä¿è¾“å‡ºåŒ…å« `images` æ–‡ä»¶å¤¹å’Œ `sparse/0` æ–‡ä»¶å¤¹ï¼ˆåŒ…å« `cameras.bin`, `images.bin`, `points3D.bin`ï¼‰ã€‚
3.  å°†ç»“æœæ”¾å…¥ `data/` æ–‡ä»¶å¤¹ï¼Œéµå¾ªä¸Šè¿°ç»“æ„ã€‚

### **3.3 è®­ç»ƒ**

```
python train.py -s data/dataset_name/scenen -m output_path --appearance_dim 0
```

**æ³¨æ„ï¼š**
`appearance_dim` å¿…é¡»è®¾ç½®ä¸º 0ï¼Œå› ä¸ºå®ƒç”¨äºå¤„ç†è®­ç»ƒè§†å›¾ï¼Œä¸é€‚åˆåœ¨æŸ¥çœ‹å™¨ä¸­æ¸²æŸ“ã€‚

è®­ç»ƒåï¼Œè¾“å‡ºæ–‡ä»¶å¤¹å°†å¦‚ä¸‹æ‰€ç¤ºï¼š

```
â”œâ”€â”€ cameras.json
â”œâ”€â”€ cfg_args
â”œâ”€â”€ input.ply
â”œâ”€â”€ outputs.log
â”œâ”€â”€ per_view.json
â”œâ”€â”€ point_cloud
â”‚   â””â”€â”€ iteration_30000
â”‚       â”œâ”€â”€ color_mlp.pt
â”‚       â”œâ”€â”€ cov_mlp.pt
â”‚       â”œâ”€â”€ opacity_mlp.pt
â”‚       â””â”€â”€ point_cloud.ply
â”œâ”€â”€ results.json
â”œâ”€â”€ test
â”‚   â””â”€â”€ ours_30000
â”‚       â”œâ”€â”€ errors
â”‚       â”œâ”€â”€ gt
â”‚       â”œâ”€â”€ per_view_count.json
â”‚       â””â”€â”€ renders
â””â”€â”€ train
    â””â”€â”€ ours_30000
        â”œâ”€â”€ gt
        â”œâ”€â”€ per_view_count.json
        â””â”€â”€ renders
```

### **3.4 å¯¼å‡º ONNX**

åœ¨ Scaffold-GS ç¯å¢ƒä¸­ï¼Œä½¿ç”¨å¯¼å‡ºè„šæœ¬ï¼ˆç¡®ä¿æ‚¨ä½äº `onnx-export\ONNXExample-scaffold` ç›®å½•ç»“æ„ä¸­ï¼‰ï¼š

```bash
cd onnx-export\ONNXExample-scaffold

python onnx_template.py --ply output_path/point_cloud/iteration_30000/point_cloud.ply \
                        --cfg_args output_path/cfg_args \
                        --out gaussians3d_scaffold.onnx
```

---

## 4. é€šç”¨ 3DGS æ ¼å¼è½¬æ¢å·¥å…·

æœ¬èŠ‚ä»‹ç»äº†å¦‚ä½•å°†æ ‡å‡† 3DGS è¾“å‡º (PLY) è½¬æ¢ä¸ºæŸ¥çœ‹å™¨æ”¯æŒçš„å„ç§ä¼˜åŒ–æ ¼å¼ã€‚

### **æ”¯æŒçš„æ ¼å¼ä¸å·¥å…·**

| æ ¼å¼ | æ‰©å±•å | å‚è€ƒé¡¹ç›® | ç”Ÿæˆ / è½¬æ¢æ–¹æ³• |
| :--- | :--- | :--- | :--- |
| **æ ‡å‡†** | `.ply` | [Inria 3DGS](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/) | ç›´æ¥ä¸‹è½½æˆ–è®­ç»ƒå¯¼å‡º |
| **å‹ç¼©ç‰ˆ** | `.compressed.ply` | [SuperSplat](https://github.com/playcanvas/supersplat) | [splat-transform](https://github.com/playcanvas/splat-transform) |
| **Splat** | `.splat` | [antimatter15/splat](https://github.com/antimatter15/splat) | [SuperSplat Editor](https://playcanvas.com/supersplat/editor) |
| **SPZ** | `.spz` | [nianticlabs/spz](https://github.com/nianticlabs/spz) | [Converting PLY to SPZ](https://github.com/nianticlabs/spz/blob/main/src/python/README.md#converting-ply-to-spz) |
| **KSplat** | `.ksplat` | [GaussianSplats3D](https://github.com/mkkellogg/GaussianSplats3D) | [GaussianSplats3D æ¼”ç¤ºé¡µé¢](https://projects.markkellogg.org/threejs/demo_gaussian_splats_3d.php) |
| **SOG** | `.sog` | [splat-transform](https://github.com/playcanvas/splat-transform) | [splat-transform](https://github.com/playcanvas/splat-transform) |


### **è½¬æ¢å‘½ä»¤**

**1. å‹ç¼©ç‰ˆ PLY & SOG**
éœ€è¦ `splat-transform`:
```bash
npm install -g @playcanvas/splat-transform
splat-transform input.ply output.compressed.ply
splat-transform input.ply output.sog
```

**2. SPZ (.spz)**
å‚è€ƒå®˜æ–¹æ–‡æ¡£ä¸­çš„è½¬æ¢æŒ‡å—ï¼š
[Converting PLY to SPZ](https://github.com/nianticlabs/spz/blob/main/src/python/README.md#converting-ply-to-spz)

**3. KSplat (.ksplat)**
éœ€è¦ Node.js:
```bash
git clone https://github.com/mkkellogg/GaussianSplats3D.git
cd GaussianSplats3D && npm install && npm run build
node util/create-ksplat.js input.ply output.ksplat
```
æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨ [GaussianSplats3D æ¼”ç¤ºé¡µé¢](https://projects.markkellogg.org/threejs/demo_gaussian_splats_3d.php) ç›´æ¥å¯¼å‡º `.ksplat` æ ¼å¼ã€‚

**4. Splat (.splat)**
ä½¿ç”¨åŸºäº Web çš„ [SuperSplat ç¼–è¾‘å™¨](https://playcanvas.com/supersplat/editor) åŠ è½½ `.ply` å¹¶å¯¼å‡ºä¸º `.splat`ã€‚

---

## 5. ç»“æœå¯è§†åŒ–

ä¸€æ—¦ç”Ÿæˆäº†æ¨¡å‹ï¼ˆONNX, PLY, Splat ç­‰ï¼‰ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„æŸ¥çœ‹å™¨è¿›è¡Œå¯è§†åŒ–ã€‚

**æŸ¥çœ‹ç»“æœï¼š**
æ‰¾åˆ°ç”Ÿæˆçš„ ONNX æ¨¡å‹ï¼ˆé€šå¸¸åœ¨ Avatar çš„ `./outputs/onnx` ç›®å½•ä¸­ï¼Œæˆ– 4DGS/Scaffold çš„ `--out` æŒ‡å®šè·¯å¾„ä¸­ï¼‰å¹¶å°†å…¶ä¸Šä¼ åˆ° [Visionary ç½‘ç«™](https://ai4sports.opengvlab.com/index_visionary.html)ã€‚

---

## ğŸ™ è‡´è°¢

æˆ‘ä»¬è¡·å¿ƒæ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®çš„ä½œè€…åšå‡ºçš„ç²¾å½©å·¥ä½œï¼Œæ­£æ˜¯è¿™äº›å·¥ä½œä½¿ Visionary æˆä¸ºå¯èƒ½ï¼š

*   **Animatable Avatar:** [LHM](https://github.com/aigc3d/LHM)
*   **4DGS:** [4D-GS](https://github.com/hustvl/4DGaussians) å’Œ [TiNeuVox](https://github.com/hustvl/TiNeuVox)
*   **Scaffold-GS:** [Scaffold-GS](https://github.com/city-super/Scaffold-GS)
*   **Viewers & Compression:** [Inria 3DGS](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/), [SuperSplat](https://github.com/playcanvas/supersplat), [GaussianSplats3D](https://github.com/mkkellogg/GaussianSplats3D), [spz](https://github.com/nianticlabs/spz).

## ğŸ“š å¼•ç”¨

å¦‚æœæ‚¨å‘ç°è¿™äº›ç®—æ³•å¯¹æ‚¨çš„ç ”ç©¶æœ‰ç”¨ï¼Œè¯·è€ƒè™‘å¼•ç”¨åŸå§‹è®ºæ–‡ï¼š
```bibtex
% 3D Gaussian Splatting (Original)
@article{kerbl3Dgaussians,
    author = {Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George},
    title = {3D Gaussian Splatting for Real-Time Radiance Field Rendering},
    journal = {ACM Transactions on Graphics},
    number = {4},
    volume = {42},
    month = {July},
    year = {2023},
    url = {https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/}
}

% Scaffold-GS
@inproceedings{scaffoldgs,
  title={Scaffold-gs: Structured 3d gaussians for view-adaptive rendering},
  author={Lu, Tao and Yu, Mulin and Xu, Linning and Xiangli, Yuanbo and Wang, Limin and Lin, Dahua and Dai, Bo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20654--20664},
  year={2024}
}

% Animatable Avatar
@article{qiu2025lhm,
  title={Lhm: Large animatable human reconstruction model from a single image in seconds},
  author={Qiu, Lingteng and Gu, Xiaodong and Li, Peihao and Zuo, Qi and Shen, Weichao and Zhang, Junfei and Qiu, Kejie and Yuan, Weihao and Chen, Guanying and Dong, Zilong and others},
  journal={arXiv preprint arXiv:2503.10625},
  year={2025}
}

@inproceedings{hu2024gauhuman,
  title={Gauhuman: Articulated gaussian splatting from monocular human videos},
  author={Hu, Shoukang and Hu, Tao and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={20418--20431},
  year={2024}
}

@article{zhan2025r3,
  title={R3-Avatar: Record and Retrieve Temporal Codebook for Reconstructing Photorealistic Human Avatars},
  author={Zhan, Yifan and Xu, Wangze and Zhu, Qingtian and Niu, Muyao and Ma, Mingze and Liu, Yifei and Zhong, Zhihang and Sun, Xiao and Zheng, Yinqiang},
  journal={arXiv preprint arXiv:2503.12751},
  year={2025}
}

% 4D Gaussian Splatting
@article{wu20234d,
  title={4d gaussian splatting for real-time dynamic scene rendering},
  author={Wu, Guanjun and Yi, Taoran and Fang, Jiemin and Xie, Lingxi and Zhang, Xiaopeng and Wei, Wei and Liu, Wenyu and Tian, Qi and Wang, Xinggang},
  journal={arXiv preprint arXiv:2310.08528},
  year={2023}
}

@inproceedings{TiNeuVox,
  author = {Fang, Jiemin and Yi, Taoran and Wang, Xinggang and Xie, Lingxi and Zhang, Xiaopeng and Liu, Wenyu and Nie\ss{}ner, Matthias and Tian, Qi},
  title = {Fast Dynamic Radiance Fields with Time-Aware Neural Voxels},
  year = {2022},
  booktitle = {SIGGRAPH Asia 2022 Conference Papers}
}

```